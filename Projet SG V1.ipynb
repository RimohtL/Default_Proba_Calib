{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet Societe Generale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Léon Thomir - Irénée De Leusse - Amaury - Louis Bolzinger*  \n",
    "CentraleSupélec 3A MMF - Société Générale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma\n",
    "from math import pi\n",
    "#pip install fbm==0.1.0\n",
    "from fbm import FBM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import et cleaning de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"C:/Users/louis/OneDrive - De Vinci/CENTRALE SUPELEC/Projet/Data issuers.xlsx\"\n",
    "market_cap = pd.read_excel(file, sheet_name=\"Mod Market Cap\")\n",
    "market_cap = market_cap.set_index(\"Dates\").loc['2019-10-28':'2020-10-13']\n",
    "debt = pd.read_excel(file, sheet_name=\"Gross Debt\", nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilité de défault & Merton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de Merton 'Classique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSM(ticker, market_cap, debt, T=1, frequency=252, rf=0, epsilon=10e-5):\n",
    "    company_debt = debt[[ticker]].iloc[0, 0]\n",
    "    company_market_cap = market_cap[[ticker]].iloc[:, 0]\n",
    "    current_time = 0\n",
    "    equity_value = 0\n",
    "    sigma_A = 0\n",
    "    sigma_A_former = 0\n",
    "    asset_values = []\n",
    "\n",
    "    def d1_m(x, sigma_A, current_time):\n",
    "        return ((np.log(x / company_debt)) + (rf + 0.5 * sigma_A ** 2) * current_time) / (\n",
    "                sigma_A * np.sqrt(current_time))\n",
    "\n",
    "    def d2_m(x, sigma_A, current_time):\n",
    "        return d1_m(x, sigma_A, current_time) - sigma_A * np.sqrt(current_time)\n",
    "\n",
    "    # inverse the black scholes formula\n",
    "    def merton_formula(x, rf, current_time):\n",
    "        d1_term = x * norm.cdf(d1_m(x, sigma_A, current_time))\n",
    "        d2_term = company_debt * np.exp(-rf * current_time) * norm.cdf(d2_m(x, sigma_A, current_time))\n",
    "        return d1_term - d2_term - equity_value\n",
    "\n",
    "    sigma_E = np.std(np.diff(np.log(company_market_cap), n=1)) * np.sqrt(frequency)\n",
    "    sigma_A = sigma_E\n",
    "\n",
    "    while np.abs(sigma_A - sigma_A_former) > epsilon:\n",
    "\n",
    "        asset_values = []\n",
    "\n",
    "        for dt in range(company_market_cap.shape[0]):\n",
    "            current_time = T + (frequency - dt - 1) / frequency\n",
    "            equity_value = company_market_cap[dt]\n",
    "            # find zero of Merton function, ie asset_value at the current_time\n",
    "            asset_values.append(optimize.newton(merton_formula, company_debt, args=(rf, current_time)))\n",
    "\n",
    "        # update of sigma_A and sigma_A_former\n",
    "        sigma_A_former = sigma_A\n",
    "        sigma_A = np.std(np.diff(np.log(asset_values), n=1)) * np.sqrt(frequency)\n",
    "\n",
    "    # compute distance to default and default probability\n",
    "    distance_to_default = d2_m(asset_values[-1], sigma_A, current_time)\n",
    "    default_probability = (1 - norm.cdf(distance_to_default)) * 100\n",
    "\n",
    "    distance_to_default_real = -d2_m(asset_values[-1], sigma_A, current_time)\n",
    "    default_probability_real = norm.cdf(distance_to_default) * 100 # notation approximation : non default probability\n",
    "    #print(distance_to_default_real)\n",
    "    #print(default_probability_real)\n",
    "\n",
    "    return sigma_A, distance_to_default, default_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de Merton avec Mouvement Brownien fractionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_values_regression_fixed_intercept(Var, delta_t, sigma_A, iteration, plot=False):\n",
    "    var_tau = np.array(Var)\n",
    "\n",
    "    # Transformation logarithmique\n",
    "    log_delta_t = np.log(delta_t)\n",
    "    log_var_tau = np.log(var_tau)\n",
    "\n",
    "    fixed_intercept_log_sigma2 = np.log(var_tau[0]) # assuming delta = 1 otherwise H is here\n",
    "\n",
    "    # Régression linéaire\n",
    "    X = log_delta_t.reshape(-1, 1)\n",
    "    y = log_var_tau - fixed_intercept_log_sigma2\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X, y)\n",
    "    #print('Regression score for H is ',model.score(X, y))\n",
    "\n",
    "    # Coefficients de la régression\n",
    "    slope = model.coef_[0]\n",
    "\n",
    "    # Calcul de H\n",
    "    H = slope / 2\n",
    "    sigma_A_former = sigma_A\n",
    "    sigma_A = np.sqrt(var_tau[0]) * ((int(252/delta_t[0]))**(H))\n",
    "\n",
    "    if plot:\n",
    "        plt.scatter(log_delta_t, y, label='Données')\n",
    "        plt.plot(log_delta_t, model.predict(log_delta_t.reshape(-1, 1)), color='red', label='Régression linéaire')\n",
    "        plt.xlabel('log(Delta t)')\n",
    "        plt.ylabel('log(Var(tau(Delta t)))')\n",
    "        plt.title(f\"Régression de l'itération {iteration}\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return sigma_A, sigma_A_former, H\n",
    "\n",
    "#d2_hurst is used to calculate the default probability\n",
    "def d1_hurst(x, sigma_A, t, T ,H, rf, company_debt):\n",
    "    return ((np.log(x / company_debt)) + rf * (T-t) + (0.5 * sigma_A ** 2) * (T ** (2 * H) - t ** (2 * H))) / (\n",
    "            sigma_A * (T - t)**H)\n",
    "def d2_hurst(x, sigma_A, t, T, H, rf, company_debt):\n",
    "    return d1_hurst(x, sigma_A, t, T, H, rf, company_debt) - sigma_A * (T - t)**H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapted Merton Formula From Necula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1 and d2 from Necula\n",
    "def d1(x, sigma_A, t, T, H, rf, company_debt):\n",
    "    return ((np.log(x / company_debt)) + rf * (T - t) + 0.5 * sigma_A ** 2 * (T ** (2 * H) - t ** (2 * H)) / (\n",
    "            sigma_A * np.sqrt(T ** (2 * H) - t ** (2 * H))))\n",
    "\n",
    "\n",
    "def d2(x, sigma_A, t, T, H, rf, company_debt):\n",
    "    return ((np.log(x / company_debt)) + rf * (T - t) - 0.5 * sigma_A ** 2 * (T ** (2 * H) - t ** (2 * H)) / (\n",
    "            sigma_A * np.sqrt(T ** (2 * H) - t ** (2 * H))))\n",
    "\n",
    "\n",
    "# inverse the black scholes formula with Necula's expresions for d1 and d2\n",
    "def merton_formula(x, rf, t, T, H, company_debt, equity_value, sigma_A):\n",
    "    d1_term = x * norm.cdf(d1(x, sigma_A, t, T, H, rf, company_debt))\n",
    "    d2_term = company_debt * np.exp(-rf * (T - t)) * norm.cdf(d2(x, sigma_A, t, T, H, rf, company_debt))\n",
    "    return d1_term - d2_term - equity_value\n",
    "\n",
    "\n",
    "def BSM_H(ticker, market_cap, debt, T=1, delta=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], rf=0, epsilon=10e-3, H0=0.5):\n",
    "    frequency = []\n",
    "    for d in delta:\n",
    "        frequency.append(252 // d)\n",
    "    company_debt = debt[[ticker]].iloc[0, 0]\n",
    "    company_market_cap = market_cap[[ticker]].iloc[:, 0]\n",
    "    sigma_A_former = 0\n",
    "    H = H0\n",
    "    sigma_E = np.std(np.diff(np.log(company_market_cap), n=1)) * np.sqrt(frequency[0])\n",
    "    sigma_A = sigma_E\n",
    "\n",
    "    n_iter = 1\n",
    "    while np.abs(sigma_A - sigma_A_former) > epsilon:\n",
    "        #print(\"Iteration \", n_iter)\n",
    "        asset_values = {}\n",
    "        for f in frequency:\n",
    "            fasset_values = []\n",
    "            n = company_market_cap.shape[0]\n",
    "            days = []\n",
    "            for i in range(n):\n",
    "                if i % (n // f) == 0:\n",
    "                    days.append(i)\n",
    "            for day in days:\n",
    "                t = day / n\n",
    "                equity_value = company_market_cap[day]\n",
    "                # find zero of Merton function, ie asset_value at the current_time\n",
    "                fasset_values.append(optimize.newton(merton_formula, company_debt,\n",
    "                                                     args=(rf, t, 1 + T, H, company_debt, equity_value, sigma_A),\n",
    "                                                     maxiter=100))\n",
    "            asset_values[f] = fasset_values\n",
    "\n",
    "        # update values\n",
    "        Var = []\n",
    "        for i, f in enumerate(frequency):\n",
    "            Var.append(np.var(np.diff(np.log(asset_values[f]), n=1)) )# *f)\n",
    "\n",
    "        Mean = []\n",
    "        for i, f in enumerate(frequency):\n",
    "            Mean.append(np.mean(np.diff(np.log(asset_values[f]), n=1)))# *f)\n",
    "\n",
    "        n_iter += 1\n",
    "        #print(\"update values\")\n",
    "        sigma_A, sigma_A_former, H = update_values_regression_fixed_intercept(Var, delta, sigma_A, n_iter, False)\n",
    "        #print(f\"sigma= {sigma_A}, H={H}\")\n",
    "\n",
    "    assert len(Mean) == len(delta)\n",
    "    mu = [round((Mean[k] + ((sigma_A**2)/(2*t)) * ((t+delta[k])**(2*H+1) - t**(2*H+1) - delta[k]**(2*H+1)) / (2*H+1)) / delta[k], 3) for k in range(len(delta))]\n",
    "    #print(mu)\n",
    "    # compute distance to default and default probability\n",
    "    t = 1\n",
    "    distance_to_default = d2_hurst(asset_values[frequency[0]][-1], sigma_A, t, t + T, H, mu[-1], company_debt)\n",
    "    default_probability = (1 - norm.cdf(distance_to_default)) * 100\n",
    "    return distance_to_default, default_probability, H, sigma_A, sigma_A_former,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapted Merton formula from Rostek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ro_h(H):\n",
    "    if H!=0.5:\n",
    "        return( (np.sin(pi*(H-0.5))/(pi*(H-0.5)))*((gamma(1.5-H)**2)/(gamma(2-2*H))) )\n",
    "    return( (gamma(1.5-H)**2)/(gamma(2-2*H)))\n",
    "\n",
    "\n",
    "def d1_rostek(x, sigma_A, t, T, H, rf, company_debt, roH):\n",
    "    return(\n",
    "       ((np.log(x / company_debt)) + rf * (T-t) + 0.5* roH * ((sigma_A )** 2 )* ((T-t)**(2*H)))\n",
    "       /(np.sqrt(roH)*sigma_A*((T-t)**H))\n",
    "    )\n",
    "\n",
    "def d2_rostek(x, sigma_A, t, T, H, rf, company_debt, roH):\n",
    "    return(\n",
    "        d1_rostek(x, sigma_A, t, T, H, rf, company_debt, roH) - np.sqrt(roH)*sigma_A*((T-t)**H)\n",
    "    )\n",
    "\n",
    "\n",
    "def merton_formula_rostek(x, rf, t, T, H, company_debt, equity_value, sigma_A, roH):\n",
    "    d1_term=x * norm.cdf(d1_rostek(x, sigma_A, t, T, H, rf, company_debt, roH))\n",
    "    d2_term=company_debt * np.exp(-rf * (T - t)) * norm.cdf(d2_rostek(x, sigma_A, t, T, H, rf, company_debt, roH))\n",
    "    return (d1_term - d2_term - equity_value)\n",
    "\n",
    "\n",
    "def BSM_H_rostek(ticker, market_cap, debt, T=1, delta=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], rf=0, epsilon=10e-3, H0=0.5):\n",
    "    frequency = []\n",
    "    for d in delta:\n",
    "        frequency.append(252 // d)\n",
    "    company_debt = debt[[ticker]].iloc[0, 0]\n",
    "    company_market_cap = market_cap[[ticker]].iloc[:, 0]\n",
    "    sigma_A_former = 0\n",
    "    H = H0\n",
    "    roH= ro_h(H)\n",
    "    sigma_E = np.std(np.diff(np.log(company_market_cap), n=1)) * np.sqrt(frequency[0])\n",
    "    sigma_A = sigma_E\n",
    "\n",
    "    n_iter = 1\n",
    "    while np.abs(sigma_A - sigma_A_former) > epsilon:\n",
    "        #print(\"Iteration \", n_iter)\n",
    "        asset_values = {}\n",
    "        for f in frequency:\n",
    "            fasset_values = []\n",
    "            n = company_market_cap.shape[0]\n",
    "            days = []\n",
    "            for i in range(n):\n",
    "                if i % (n // f) == 0:\n",
    "                    days.append(i)\n",
    "            for day in days:\n",
    "                t = day / n\n",
    "                equity_value = company_market_cap[day]\n",
    "                # find zero of Merton function, ie asset_value at the current_time\n",
    "                fasset_values.append(optimize.newton(merton_formula_rostek, company_debt,\n",
    "                                                     args=(rf, t, 1 + T, H, company_debt, equity_value, sigma_A,roH),\n",
    "                                                     maxiter=100))\n",
    "            asset_values[f] = fasset_values\n",
    "\n",
    "        # update values\n",
    "        Var = []\n",
    "        for i, f in enumerate(frequency):\n",
    "            Var.append(np.var(np.diff(np.log(asset_values[f]), n=1)) )# *f)\n",
    "\n",
    "        Mean = []\n",
    "        for i, f in enumerate(frequency):\n",
    "            Mean.append(np.mean(np.diff(np.log(asset_values[f]), n=1)))# *f)\n",
    "\n",
    "        n_iter += 1\n",
    "        #print(\"update values\")\n",
    "        sigma_A, sigma_A_former, H = update_values_regression_fixed_intercept(Var, delta, sigma_A, n_iter, plot=False)\n",
    "        roH= ro_h(H)\n",
    "        #print(f\"sigma= {sigma_A}, H={H}\")\n",
    "\n",
    "    assert len(Mean) == len(delta)\n",
    "    mu = [round((Mean[k] + ((sigma_A**2)/(2*t)) * ((t+delta[k])**(2*H+1) - t**(2*H+1) - delta[k]**(2*H+1)) / (2*H+1)) / delta[k], 3) for k in range(len(delta))]\n",
    "    #print(mu)\n",
    "    # compute distance to default and default probability\n",
    "    t = 1\n",
    "    distance_to_default = d2_hurst(asset_values[frequency[0]][-1], sigma_A, t, t + T, H, mu[-1], company_debt)\n",
    "    default_probability = (1 - norm.cdf(distance_to_default)) * 100\n",
    "    return distance_to_default, default_probability, H, sigma_A, sigma_A_former\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implémentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_proba_default(index_ticker = 0, maturity = [1, 2, 5, 10, 15], display_graphe = True, display_H_coeff = True, ticker = False, metric = 'default'): \n",
    "    if ticker == False :  \n",
    "        ticker = market_cap.columns[index_ticker]\n",
    "\n",
    "    proba_merton = np.zeros(len(maturity))\n",
    "    proba_necula = np.zeros(len(maturity))\n",
    "    proba_rostek = np.zeros(len(maturity))\n",
    "\n",
    "    if metric == 'default': \n",
    "        index_merton = 2\n",
    "        index_necula_rostek = 1\n",
    "    elif metric == 'sigma': \n",
    "            index_merton = 0\n",
    "            index_necula_rostek = 3 \n",
    "    for i, m in enumerate(maturity):\n",
    "        proba_merton[i] = BSM(ticker, market_cap, debt, T=m)[index_merton]\n",
    "        proba_necula[i] = BSM_H(ticker, market_cap, debt, T=m)[index_necula_rostek]\n",
    "        proba_rostek[i] = BSM_H_rostek(ticker, market_cap, debt, T=m)[index_necula_rostek]\n",
    "    \n",
    "    Hurst_coef = BSM_H(ticker, market_cap, debt, T=1)[2]\n",
    "\n",
    "    if display_H_coeff :  print(f\"{ticker} Hurst : {Hurst_coef}\")\n",
    "    if display_graphe : \n",
    "        plt.figure()\n",
    "        plt.plot(maturity, proba_merton, label=\"Merton\")\n",
    "        plt.plot(maturity, proba_necula, label=\"Necula\")\n",
    "        plt.plot(maturity, proba_rostek, label=\"Rostek\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Proba de défaut selon la maturité T pour {ticker}\")\n",
    "        plt.xlabel(\"T\")\n",
    "        plt.ylabel(\"Proba\")\n",
    "        plt.show()\n",
    "    \n",
    "    return proba_merton, proba_necula, proba_rostek, Hurst_coef\n",
    "\n",
    "def export_latex(liste_ticker, maturity = [1, 2, 5, 10], metric = 'default'): \n",
    "    for maturity in maturity: \n",
    "        export = ''\n",
    "        if metric == 'default': \n",
    "            index_merton = 2\n",
    "            index_necula_rostek = 1\n",
    "        elif metric == 'sigma': \n",
    "            index_merton = 0\n",
    "            index_necula_rostek = 3\n",
    "        for ticker in liste_ticker: \n",
    "            export  += str(ticker)\n",
    "            export += ' & '\n",
    "            proba_merton = BSM(ticker, market_cap, debt, T=maturity)[index_merton]\n",
    "            export += str(proba_merton) + ' & '\n",
    "            proba_necula = BSM_H(ticker, market_cap, debt, T=maturity)[index_necula_rostek]\n",
    "            export += str(proba_necula) + ' & '\n",
    "            proba_rostek = BSM_H_rostek(ticker, market_cap, debt, T=maturity)[index_necula_rostek]\n",
    "            export += str(proba_rostek) + ' & '\n",
    "            Hurst_coef = BSM_H(ticker, market_cap, debt, T=1)[2]\n",
    "            export += str(Hurst_coef) + ' \\\\ \\n'\n",
    "        print(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_proba_default(ticker = 'FGR FP Equity', metric = 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_equity = ['FGR FP Equity', \n",
    "                'CRH LN Equity', \n",
    "                'FR FP Equity' , \n",
    "                'ADP FP Equity' , \n",
    "                'DAI GY Equity', \n",
    "                'VIE FP Equity', \n",
    "                'LHA GY Equity', \n",
    "                'CO FP Equity']\n",
    "export_latex(liste_equity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouvement Brownien Fractionnaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec des résultats simulés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evol_va(mu,sigma_a,fbm_sample,times,H):\n",
    "    VA=np.exp( mu*times - ((sigma_a**2)/2)*(times**(2*H)) + sigma_a*fbm_sample)\n",
    "    return(VA)\n",
    "\n",
    "def genhurst(S, q):\n",
    "    \"\"\"\n",
    "    S : série temporelle\n",
    "    q : ordre \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtient la longueur de la série temporelle\n",
    "    L = len(S)\n",
    "\n",
    "    # Avertissement si la série temporelle est très courte (moins de 100 points)\n",
    "    #if L < 100:\n",
    "    #    warnings.warn('Data series very short!')\n",
    "\n",
    "    # Initialisation d'un tableau H pour stocker les résultats du coefficient de Hurst\n",
    "    H = np.zeros((len(range(5, 20)), 1))  # Crée un tableau de zéros de forme (15, 1)\n",
    "    k = 0  # Initialise un compteur\n",
    "\n",
    "    # Boucle sur différentes fenêtres de temps (Tmax)\n",
    "    for Tmax in range(5, 20):\n",
    "\n",
    "        # Génère une séquence de nombres de 1 à Tmax\n",
    "        x = np.arange(1, Tmax + 1, 1)\n",
    "\n",
    "        # Initialise un tableau mcord pour stocker les résultats locaux du coefficient de Hurst\n",
    "        mcord = np.zeros((Tmax, 1))  # Crée un tableau de zéros de forme (Tmax, 1)\n",
    "\n",
    "        # Boucle à travers les décalages temporels (tt) dans la fenêtre actuelle\n",
    "        for tt in range(1, Tmax + 1):\n",
    "\n",
    "            # Calcule les différences et les valeurs retardées\n",
    "            dV = S[np.arange(tt, L, tt)] - S[np.arange(tt, L, tt) - tt]\n",
    "            VV = S[np.arange(tt, L + tt, tt) - tt]\n",
    "            N = len(dV) + 1\n",
    "            X = np.arange(1, N + 1, dtype=np.float64)\n",
    "            Y = VV\n",
    "\n",
    "            # Calcul des coefficients pour ajuster une droite\n",
    "            mx = np.sum(X) / N\n",
    "            SSxx = np.sum(X**2) - N * mx**2\n",
    "            my = np.sum(Y) / N\n",
    "            SSxy = np.sum(np.multiply(X, Y)) - N * mx * my\n",
    "            cc1 = SSxy / SSxx\n",
    "            cc2 = my - cc1 * mx\n",
    "            ddVd = dV - cc1\n",
    "            VVVd = VV - np.multiply(cc1, np.arange(1, N + 1, dtype=np.float64)) - cc2\n",
    "\n",
    "            # Calcul du coefficient de Hurst local\n",
    "            mcord[tt - 1] = np.mean(np.abs(ddVd)**q) / np.mean(np.abs(VVVd)**q)\n",
    "\n",
    "        # Régression linéaire sur le logarithme des échelles\n",
    "        mx = np.mean(np.log10(x))\n",
    "        SSxx = np.sum(np.log10(x)**2) - Tmax * mx**2\n",
    "        my = np.mean(np.log10(mcord))\n",
    "        SSxy = np.sum(np.multiply(np.log10(x), np.transpose(np.log10(mcord)))) - Tmax * mx * my\n",
    "\n",
    "        # Stocke le résultat du coefficient de Hurst dans le tableau H\n",
    "        H[k] = SSxy / SSxx\n",
    "        k = k + 1\n",
    "\n",
    "    # Calcule la moyenne des coefficients de Hurst sur toutes les fenêtres de temps et divise par q\n",
    "    mH = np.mean(H) / q\n",
    "\n",
    "    return mH  # Retourne le coefficient de Hurst moyen divisé par l'ordre q\n",
    "\n",
    "\n",
    "def find_H(VA):\n",
    "    n = VA.shape[0]\n",
    "\n",
    "    delta_t=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    frequency = []\n",
    "    for d in delta_t:\n",
    "        frequency.append(n // d)\n",
    "    \n",
    "    #resampe with different frequencies\n",
    "    asset_values={}\n",
    "    for f in frequency:\n",
    "        fasset_values = []\n",
    "        days = []\n",
    "        for i in range(n):\n",
    "            if i % (n // f) == 0 :\n",
    "                days.append(i)\n",
    "        for day in days:\n",
    "            fasset_values.append(VA[day])\n",
    "        asset_values[f] = fasset_values\n",
    "\n",
    "    #calculate Variance and Mean for every frequency\n",
    "    Var = []\n",
    "    for i, f in enumerate(frequency):\n",
    "        Var.append(np.var(np.diff(np.log(asset_values[f]), n=1)) )\n",
    "\n",
    "    Mean = []\n",
    "    for i, f in enumerate(frequency):\n",
    "        Mean.append(np.mean(np.diff(np.log(asset_values[f]), n=1)))\n",
    "    var_tau = np.array(Var)\n",
    "\n",
    "\n",
    "    # Transformation logarithmique\n",
    "    log_delta_t = np.log(delta_t)\n",
    "    log_var_tau = np.log(var_tau)\n",
    "\n",
    "    fixed_intercept_log_sigma2 = np.log(var_tau[0]) # assuming delta = 1 otherwise H is here\n",
    "\n",
    "    # Régression linéaire\n",
    "    X = log_delta_t.reshape(-1, 1)\n",
    "    y = log_var_tau - fixed_intercept_log_sigma2\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X, y)\n",
    "    #print('Regression score for H is ',model.score(X, y))\n",
    "\n",
    "    # Coefficients de la régression\n",
    "    slope = model.coef_[0]\n",
    "\n",
    "    # Calcul de H\n",
    "    H = slope / 2\n",
    "    sigma_A = np.sqrt(var_tau[0]) * np.sqrt(int(n/delta_t[0]))\n",
    "    #for i in range(len(delta_t)):\n",
    "    #    print(np.sqrt(var_tau[i]) * np.sqrt(int(n/delta_t[i])))\n",
    "\n",
    "    return sigma_A, H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 to obtain sigma and H. Sigma is obtained from H (more potential error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_H_sigma(VA):\n",
    "    n = VA.shape[0]\n",
    "\n",
    "    delta_t=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    frequency = []\n",
    "    for d in delta_t:\n",
    "        frequency.append(n // d)\n",
    "    \n",
    "    #resampe with different frequencies\n",
    "    asset_values={}\n",
    "    for f in frequency:\n",
    "        fasset_values = []\n",
    "        days = []\n",
    "        for i in range(n):\n",
    "            if i % (n // f) == 0 :\n",
    "                days.append(i)\n",
    "        for day in days:\n",
    "            fasset_values.append(VA[day])\n",
    "        asset_values[f] = fasset_values\n",
    "\n",
    "    #calculate Variance and Mean for every frequency\n",
    "    Var = []\n",
    "    for i, f in enumerate(frequency):\n",
    "        Var.append(np.var(np.diff(np.log(asset_values[f]), n=1)) )\n",
    "\n",
    "    Mean = []\n",
    "    for i, f in enumerate(frequency):\n",
    "        Mean.append(np.mean(np.diff(np.log(asset_values[f]), n=1)))\n",
    "    var_tau = np.array(Var)\n",
    "\n",
    "\n",
    "    # Transformation logarithmique\n",
    "    log_delta_t = np.log(delta_t)\n",
    "    log_var_tau = np.log(var_tau)\n",
    "\n",
    "    fixed_intercept_log_sigma2 = np.log(var_tau[0]) # assuming delta = 1 otherwise H is here\n",
    "\n",
    "    # Régression linéaire\n",
    "    X = log_delta_t.reshape(-1, 1)\n",
    "    y = log_var_tau - fixed_intercept_log_sigma2\n",
    "\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X, y)\n",
    "    #print('Regression score for H is ',model.score(X, y))\n",
    "\n",
    "    # Coefficients de la régression\n",
    "    slope = model.coef_[0]\n",
    "\n",
    "    # Calcul de H\n",
    "    H = slope / 2\n",
    "    sigma_A = np.sqrt(var_tau[0]) * ((int(n/delta_t[0]))**(H))\n",
    "    #for i in range(len(delta_t)):\n",
    "    #    print(np.sqrt(var_tau[i]) * np.sqrt(int(n/delta_t[i])))\n",
    "\n",
    "    return sigma_A, H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2. The Calculation for Sigma appears different but it is in fact the same (from Cajueiro, Daniel O. and Fajardo, José, Volatility Estimation and Option Pricing with Fractional Brownian Motion (October 27, 2005). Available at SSRN: https://ssrn.com/abstract=837765 or http://dx.doi.org/10.2139/ssrn.837765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_H_sigma_2(VA,T):\n",
    "\n",
    "    ###Find H\n",
    "\n",
    "    n = VA.shape[0]\n",
    "\n",
    "    delta_t=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    frequency = []\n",
    "    for d in delta_t:\n",
    "        frequency.append(n // d)\n",
    "    \n",
    "\n",
    "    #resampe with different frequencies\n",
    "    asset_values={}\n",
    "    for f in frequency:\n",
    "        fasset_values = []\n",
    "        days = []\n",
    "        for i in range(n):\n",
    "            if i % (n // f) == 0 :\n",
    "                days.append(i)\n",
    "        for day in days:\n",
    "            fasset_values.append(VA[day])\n",
    "        asset_values[f] = fasset_values\n",
    "\n",
    "    #calculate Variance and Mean for every frequency\n",
    "    Var = []\n",
    "    for i, f in enumerate(frequency):\n",
    "        Var.append(np.var(np.diff(np.log(asset_values[f]), n=1)) )\n",
    "\n",
    "    Mean = []\n",
    "    for i, f in enumerate(frequency):\n",
    "        Mean.append(np.mean(np.diff(np.log(asset_values[f]), n=1)))\n",
    "    var_tau = np.array(Var)\n",
    "\n",
    "    \n",
    "    # Transformation logarithmique\n",
    "    log_delta_t = np.log(delta_t)\n",
    "    log_var_tau = np.log(var_tau)\n",
    "\n",
    "    fixed_intercept_log_sigma2 = np.log(var_tau[0]) # assuming delta = 1 otherwise H is here\n",
    "\n",
    "    # Régression linéaire\n",
    "    X = log_delta_t.reshape(-1, 1)\n",
    "    y = log_var_tau - fixed_intercept_log_sigma2\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X, y)\n",
    "    #print('Regression score for H is ',model.score(X, y))\n",
    "\n",
    "    # Coefficients de la régression\n",
    "    slope = model.coef_[0]\n",
    "\n",
    "    # Calcul de H\n",
    "    H = slope / 2\n",
    "\n",
    "\n",
    "    #Calcul Sigma\n",
    "    Z=np.log(VA)\n",
    "\n",
    "    DZ=Z[1:]-Z[:-1]\n",
    "    y=((n/T)**H)*DZ\n",
    "\n",
    "    sigma_est= np.sqrt((n/(n-1))*np.var(y))\n",
    "\n",
    "    return sigma_est,H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_error(true_sigma,mu,H,n,n_it=10, T=1):\n",
    "    \n",
    "    f = FBM(n, hurst=H, length=T, method='daviesharte')\n",
    "    fbm_sample = f.fbm()\n",
    "    times = f.times()\n",
    "    VA=evol_va(mu,true_sigma,fbm_sample,times,H)\n",
    "    sigma_1=find_H_sigma(VA)[0]\n",
    "    sigma_2=find_H_sigma_2(VA,T)[0]\n",
    "\n",
    "    err1=np.abs(sigma_1-true_sigma)\n",
    "    err2=np.abs(sigma_2-true_sigma)\n",
    "    return(sigma_1,sigma_2,err1,err2)\n",
    "\n",
    "def H_error(sigma_a,mu,H,n,n_it=50):\n",
    "\n",
    "    exp_h=np.zeros(n_it)\n",
    "    err_h=np.zeros(n_it)\n",
    "\n",
    "    \n",
    "    for i in range (n_it):\n",
    "        f = FBM(n, hurst=H, length=1, method='daviesharte')\n",
    "        fbm_sample = f.fbm()\n",
    "        times = f.times()\n",
    "        exp_h[i]=find_H(evol_va(mu,sigma_a,fbm_sample,times,H))[1]\n",
    "        err_h[i]=np.abs(exp_h[i]-H)\n",
    "\n",
    "    return (np.mean(exp_h),np.mean(err_h))\n",
    "\n",
    "def find_sigma(VA,H,T):\n",
    "\n",
    "    n = VA.shape[0]\n",
    "    X=np.log(VA)\n",
    "\n",
    "    DX=X[1:]-X[:-1]\n",
    "    y=((n/T)**H)*DX\n",
    "\n",
    "    sigma_est= np.sqrt((n/(n-1))*np.var(y))\n",
    "\n",
    "    return sigma_est\n",
    "\n",
    "def sigma_error2(true_sigma,mu,H,n,sigma_a,n_it=10, T=1):\n",
    "\n",
    "    f = FBM(n, hurst=H, length=T, method='daviesharte')\n",
    "    fbm_sample = f.fbm()\n",
    "    times = f.times()\n",
    "    VA=evol_va(mu,sigma_a,fbm_sample,times,H)\n",
    "    sigma_al=find_sigma(VA,H,T)\n",
    "\n",
    "    err_sigma=np.abs(sigma_al-true_sigma)\n",
    "    return(sigma_al,err_sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions d'affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_to_real_sigma(sigma_a=0.3, H=0.6, mu=0):\n",
    "    sigma_al=[]\n",
    "    err_sigma=[]\n",
    "    liste_n=[]\n",
    "\n",
    "    for n in range(100,1000,10):\n",
    "        liste_n.append(n)\n",
    "        s,e=sigma_error(sigma_a,mu,H,n,n_it=10)\n",
    "        sigma_al.append(s)\n",
    "        err_sigma.append(e)\n",
    "\n",
    "    plt.plot(liste_n,sigma_al,label=\"sigma from algorithm\")\n",
    "    plt.plot(liste_n,err_sigma,label=\"distance to real sigma_A\")\n",
    "    plt.legend()\n",
    "\n",
    "def plot_distance_to_real_H(sigma_a=0.3, H=0.6, mu=0):\n",
    "    exp_h=[]\n",
    "    err_h=[]\n",
    "    liste_n=[]\n",
    "\n",
    "    for n in range(100,1000,10):\n",
    "        liste_n.append(n)\n",
    "        s,e=H_error(sigma_a,mu,H,n,n_it=10)\n",
    "        exp_h.append(s)\n",
    "        err_h.append(e)\n",
    "\n",
    "    plt.plot(liste_n,exp_h,label=\"H from algorithm\")\n",
    "\n",
    "    plt.plot(liste_n,err_h,label=\"absolute distance to real H\")\n",
    "    plt.legend()\n",
    "\n",
    "def plot_distance_to_real_sigma_2(sigma_a=0.4, H=0.6, mu=0, T=1):\n",
    "    sigma_al=[]\n",
    "    err_sigma=[]\n",
    "    liste_n=[]\n",
    "    r_s=[]\n",
    "\n",
    "    for n in range(10,252,10):\n",
    "        liste_n.append(n)\n",
    "        s,e=sigma_error2(sigma_a,mu,H,n,sigma_a, n_it=10)\n",
    "        sigma_al.append(s)\n",
    "        err_sigma.append(e)\n",
    "        r_s.append(sigma_a)\n",
    "\n",
    "    plt.plot(liste_n,sigma_al,label=\"sigma from algorithm\")\n",
    "    plt.plot(liste_n,r_s,label=\"Sigma_A reel\")\n",
    "\n",
    "    plt.plot(liste_n,err_sigma,label=\"distance to real sigma_A\")\n",
    "    plt.legend()\n",
    "\n",
    "def plot_sigma_comparison(sigma_a=0.3, H=0.6, mu=0, T=1):\n",
    "    \n",
    "    sigma_1=[]\n",
    "    sigma_2=[]\n",
    "    err_sigma1=[]\n",
    "    err_sigma2=[]\n",
    "\n",
    "    liste_n=[]\n",
    "    r_s=[]\n",
    "\n",
    "    for n in range(50,5000,10):\n",
    "        liste_n.append(n)\n",
    "        s1,s2,e1,e2=sigma_error(sigma_a,mu,H,n,n_it=10)\n",
    "        sigma_1.append(s1)\n",
    "        sigma_2.append(s2)\n",
    "\n",
    "        #err_sigma.append(e)\n",
    "        r_s.append(sigma_a)\n",
    "\n",
    "    plt.plot(liste_n,sigma_1,label=\"sigma from method 1\")\n",
    "    plt.plot(liste_n,r_s,label=\"Sigma_A reel\")\n",
    "\n",
    "    plt.plot(liste_n,sigma_2,label=\"sigma from method 2\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implémentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_a = 0.3\n",
    "H = 0.6\n",
    "mu = 0\n",
    "T = 1\n",
    "plot_distance_to_real_sigma(sigma_a, H, mu)\n",
    "plot_distance_to_real_H(sigma_a, H, mu)\n",
    "plot_distance_to_real_sigma_2(sigma_a, H, mu, T)\n",
    "plot_sigma_comparison(sigma_a, H, mu, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouvements brownien Gris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb_gris(s,t,n_steps,H):\n",
    "\n",
    "    times=np.linspace(s,t,n_steps)\n",
    "    e = np.random.normal(size=n_steps)\n",
    "\n",
    "    mbg=((times-s)**H)*e\n",
    "    return(times,mbg)\n",
    "\n",
    "def simulate_asset_price(S0, r, sigma, T, n_steps, n_it):\n",
    "    dt = T / n_steps\n",
    "    nudt = (r - 0.5 * sigma**2) * dt\n",
    "    sigsdt = sigma * np.sqrt(dt)\n",
    "\n",
    "    S = np.zeros((n_it, n_steps + 1))\n",
    "    S[:, 0] = S0\n",
    "\n",
    "    for i in range(n_it):\n",
    "        #Draw of random walk\n",
    "        e = np.random.normal(size=n_steps)\n",
    "        for k in range(1, n_steps + 1):\n",
    "            S[i, k] = S[i, k - 1] * np.exp(nudt + sigsdt * e[k-1])\n",
    "\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implémentation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
